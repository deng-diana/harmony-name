import fs from "fs";
import path from "path";
import OpenAI from "openai";
import dotenv from "dotenv";

// åŠ è½½ç¯å¢ƒå˜é‡ (å› ä¸ºè„šæœ¬ä¸åœ¨ Next.js ç¯å¢ƒä¸‹è¿è¡Œï¼Œéœ€è¦æ‰‹åŠ¨åŠ è½½)
dotenv.config({ path: ".env.local" });

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// 1. è¯»å–åŸå§‹è¯—è¯
const poems = JSON.parse(
  fs.readFileSync(path.join(process.cwd(), "scripts/poems.json"), "utf8")
);

async function generateEmbeddings() {
  console.log(`ğŸ”¥ Starting vectorization for ${poems.length} poems...`);

  const processedPoems = [];

  for (const poem of poems) {
    // æˆ‘ä»¬æŠŠ æ ‡é¢˜+å†…å®¹+æ ‡ç­¾ ç»„åˆåœ¨ä¸€èµ·ï¼Œå˜æˆä¸€æ®µè¯ï¼Œè®© AI ç†è§£å®ƒçš„å«ä¹‰
    const textToEmbed = `${poem.title} ${poem.dynasty} ${poem.author}: ${
      poem.content
    } Keywords: ${poem.tags.join(", ")}`;

    try {
      // 2. è°ƒç”¨ OpenAI æŠŠå®ƒå˜æˆå‘é‡ (Vector)
      const response = await openai.embeddings.create({
        model: "text-embedding-3-small", // ä¸“é—¨ç”¨æ¥åšæœç´¢çš„æ¨¡å‹ï¼Œåˆå¿«åˆä¾¿å®œ
        input: textToEmbed,
        encoding_format: "float",
      });

      const embedding = response.data[0].embedding;

      // 3. æŠŠå‘é‡å­˜è¿›å¯¹è±¡é‡Œ
      processedPoems.push({
        ...poem,
        embedding, // ğŸ‘ˆ è¿™å°±æ˜¯å®ƒçš„â€œGPSåæ ‡â€
      });

      console.log(`âœ… Processed: ${poem.title}`);
    } catch (error) {
      console.error(`âŒ Failed: ${poem.title}`, error);
    }
  }

  // 4. ä¿å­˜åˆ°ä¸€ä¸ªæ–°æ–‡ä»¶ï¼šæ•°æ®åº“ï¼
  // è¿™é‡Œçš„ 'lib' æŒ‡çš„æ˜¯é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ lib æ–‡ä»¶å¤¹
  // å¦‚æœä½ çš„ lib åœ¨ src é‡Œé¢ï¼Œå°±æ”¹æˆ 'src/lib'
  const outputDir = path.join(process.cwd(), "src/lib");
  const outputPath = path.join(outputDir, "poems-db.json");

  // ğŸ›¡ï¸ ä¿é™©ä¸ï¼šå¦‚æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œå°±è‡ªåŠ¨å»ºä¸€ä¸ªï¼
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  fs.writeFileSync(outputPath, JSON.stringify(processedPoems, null, 2));

  console.log(`ğŸ‰ Success! Database saved to ${outputPath}`);
}

generateEmbeddings();
