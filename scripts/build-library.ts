import fs from 'fs';
import path from 'path';
import OpenAI from 'openai';
import dotenv from 'dotenv';

// åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config({ path: '.env.local' });

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ğŸ¯ ç°åœ¨çš„æºå¤´æ˜¯æœ¬åœ°æ–‡ä»¶ (Local Files)
const SOURCES = [
  {
    name: "Tang Poems",
    path: "src/data/tang.json", // ğŸ‘ˆ æŒ‡å‘ src/data ä¸‹çš„æ–‡ä»¶
    type: "Tang"
  },
  {
    name: "Song Ci",
    path: "src/data/song.json",
    type: "Song"
  },
  {
    name: "Shijing",
    path: "src/data/shijing.json",
    type: "Classic"
  }
];

interface RawPoem {
  title?: string;
  rhythmic?: string;
  author: string;
  paragraphs?: string[];
  content?: string[];
}

interface ProcessedPoem {
  title: string;
  author: string;
  dynasty: string;
  content: string;
  embedding: number[];
}

const sleep = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

async function buildLibrary() {
  console.log("ğŸš€ Starting Local Data Processing...");
  
  let allPoems: ProcessedPoem[] = [];

  for (const source of SOURCES) {
    console.log(`ğŸ“– Reading ${source.name}...`);
    
    try {
      // 1. è¯»å–æœ¬åœ°æ–‡ä»¶
      const filePath = path.join(process.cwd(), source.path);
      const fileContent = fs.readFileSync(filePath, 'utf-8');
      const rawData = JSON.parse(fileContent) as RawPoem[];
      
      console.log(`   Loaded ${rawData.length} poems.`);

      // 2. æ•°æ®æ¸…æ´— (å–å‰ 50 é¦–åš MVPï¼Œçœé’±ä¸”å¿«)
      // âš ï¸ æ³¨æ„ï¼šæ­£å¼ç‰ˆå¯ä»¥å»æ‰ .slice(0, 50)
      const cleanData = rawData.slice(0, 50).map(item => {
        const title = item.title || item.rhythmic || "Unknown";
        const lines = item.paragraphs || item.content || [];
        const content = lines.join("ï¼Œ");
        
        return {
          title,
          author: item.author || 'Unknown',
          dynasty: source.type,
          content
        };
      }).filter(p => p.content.length > 10);

      // 3. å‘é‡åŒ– (Vectorization)
      for (const [index, poem] of cleanData.entries()) {
        try {
          const textToEmbed = `Title:${poem.title} Author:${poem.author} Content:${poem.content}`;
          
          const embeddingResp = await openai.embeddings.create({
            model: "text-embedding-3-small",
            input: textToEmbed,
            encoding_format: "float",
          });

          allPoems.push({
            ...poem,
            embedding: embeddingResp.data[0].embedding
          });

          process.stdout.write(`\r   âœ¨ Vectorizing... ${index + 1}/${cleanData.length}`);
          await sleep(20); // ç¨å¾®å¿«ä¸€ç‚¹ï¼Œå› ä¸ºä¸ç”¨ç½‘ç»œä¸‹è½½äº†

        } catch (error) {
          console.warn(`\n   âš ï¸ Skipped "${poem.title}"`);
        }
      }
      console.log("\n   âœ… Source done.");

    } catch (err) {
      console.error(`âŒ Error reading ${source.path}. Did you create the file?`, err);
    }
  }

  // 4. ä¿å­˜æ•°æ®åº“
  const outputDir = path.join(process.cwd(), 'src/lib');
  const outputPath = path.join(outputDir, 'poems-db.json');

  if (!fs.existsSync(outputDir)) fs.mkdirSync(outputDir, { recursive: true });
  fs.writeFileSync(outputPath, JSON.stringify(allPoems, null, 2));

  console.log(`\nğŸ‰ DATABASE BUILD COMPLETE! Total Poems: ${allPoems.length}`);
  console.log(`ğŸ“‚ Saved to: ${outputPath}`);
}

buildLibrary();